{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACM Image Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Test Code to check installation of tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf1\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf1.disable_v2_behavior()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6 7]\n",
      "[ 5 12 32]\n"
     ]
    }
   ],
   "source": [
    " with tf1.Session() as ses:\n",
    "\n",
    "     # Build a graph.\n",
    "     b = tf.constant([1,2,3,4])\n",
    "     a = tf.constant([5,6,7,8])\n",
    "     d = tf.concat(a ,100)\n",
    "     c = a * b\n",
    "\n",
    "     # Evaluate the tensor `c`.\n",
    "     print(ses.run(d))\n",
    "     print(ses.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.8356345  0.1677035  5.964585   ... 0.19364221 1.0942171  3.0981884 ]\n",
      " [0.09862313 3.7217991  1.2237668  ... 0.17436002 1.029364   0.20907243]\n",
      " [1.8318801  0.73239815 0.14184146 ... 0.71591944 1.692384   0.215665  ]\n",
      " ...\n",
      " [1.2499211  0.7376043  1.6499598  ... 0.47356522 0.07113019 1.9038589 ]\n",
      " [0.01271696 0.6774325  2.4383607  ... 4.525194   3.132105   2.0728633 ]\n",
      " [0.64920354 1.3448879  4.3649774  ... 2.8003895  0.36924618 2.127932  ]]\n"
     ]
    }
   ],
   "source": [
    " with tf1.Session() as ses:\n",
    "\n",
    "     # Build a graph.\n",
    "     \n",
    "     \n",
    "     d = tf.random.uniform([1000,20000],0,1)\n",
    "     e = tf.random.uniform([1000,20000],0,7)\n",
    "     # Evaluate the tensor `c`.\n",
    "     c = d*e\n",
    "     #print(ses.run(e))\n",
    "     print(ses.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test code for CIFAR-10 as taken from a website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm \n",
    "import tarfile\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is pre-processing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_stats(cifar10_dataset_folder_path, batch_id, sample_id):\n",
    "    features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_id)\n",
    "    \n",
    "    if not (0 <= sample_id < len(features)):\n",
    "        print('{} samples in batch {}.  {} is out of range.'.format(len(features), batch_id, sample_id))\n",
    "        return None\n",
    "\n",
    "    print('\\nStats of batch #{}:'.format(batch_id))\n",
    "    print('# of Samples: {}\\n'.format(len(features)))\n",
    "    \n",
    "    label_names = load_label_names()\n",
    "    label_counts = dict(zip(*np.unique(labels, return_counts=True)))\n",
    "    for key, value in label_counts.items():\n",
    "        print('Label Counts of [{}]({}) : {}'.format(key, label_names[key].upper(), value))\n",
    "    \n",
    "    sample_image = features[sample_id]\n",
    "    sample_label = labels[sample_id]\n",
    "    \n",
    "    print('\\nExample of Image {}:'.format(sample_id))\n",
    "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
    "    print('Image - Shape: {}'.format(sample_image.shape))\n",
    "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
    "    \n",
    "    plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch #3:\n",
      "# of Samples: 10000\n",
      "\n",
      "Label Counts of [0](AIRPLANE) : 994\n",
      "Label Counts of [1](AUTOMOBILE) : 1042\n",
      "Label Counts of [2](BIRD) : 965\n",
      "Label Counts of [3](CAT) : 997\n",
      "Label Counts of [4](DEER) : 990\n",
      "Label Counts of [5](DOG) : 1029\n",
      "Label Counts of [6](FROG) : 978\n",
      "Label Counts of [7](HORSE) : 1015\n",
      "Label Counts of [8](SHIP) : 961\n",
      "Label Counts of [9](TRUCK) : 1029\n",
      "\n",
      "Example of Image 999:\n",
      "Image - Min Value: 1 Max Value: 238\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 8 Name: ship\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 3\n",
    "sample_id = 999\n",
    "display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: input image data in numpy array [32, 32, 3]\n",
    "        return\n",
    "            - normalized x \n",
    "    \"\"\"\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: a list of labels\n",
    "        return\n",
    "            - one hot encoding matrix (number of labels, number of class)\n",
    "    \"\"\"\n",
    "    encoded = np.zeros((len(x), 10))\n",
    "    \n",
    "    for idx, val in enumerate(x):\n",
    "        encoded[idx][val] = 1\n",
    "    \n",
    "    return encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_and_save(normalize, one_hot_encode, features, labels, filename):\n",
    "    features = normalize(features)\n",
    "    labels = one_hot_encode(labels)\n",
    "\n",
    "    pickle.dump((features, labels), open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode):\n",
    "    n_batches = 5\n",
    "    valid_features = []\n",
    "    valid_labels = []\n",
    "\n",
    "    for batch_i in range(1, n_batches + 1):\n",
    "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
    "        \n",
    "        # find index to be the point as validation data in the whole dataset of the batch (10%)\n",
    "        index_of_validation = int(len(features) * 0.1)\n",
    "\n",
    "        # preprocess the 90% of the whole dataset of the batch\n",
    "        # - normalize the features\n",
    "        # - one_hot_encode the lables\n",
    "        # - save in a new file named, \"preprocess_batch_\" + batch_number\n",
    "        # - each file for each batch\n",
    "        _preprocess_and_save(normalize, one_hot_encode,\n",
    "                             features[:-index_of_validation], labels[:-index_of_validation], \n",
    "                             'preprocess_batch_' + str(batch_i) + '.p')\n",
    "\n",
    "        # unlike the training dataset, validation dataset will be added through all batch dataset\n",
    "        # - take 10% of the whold dataset of the batch\n",
    "        # - add them into a list of\n",
    "        #   - valid_features\n",
    "        #   - valid_labels\n",
    "        valid_features.extend(features[-index_of_validation:])\n",
    "        valid_labels.extend(labels[-index_of_validation:])\n",
    "\n",
    "    # preprocess the all stacked validation dataset\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(valid_features), np.array(valid_labels),\n",
    "                         'preprocess_validation.p')\n",
    "\n",
    "    # load the test dataset\n",
    "    with open(cifar10_dataset_folder_path + '/test_batch', mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    # preprocess the testing data\n",
    "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    test_labels = batch['labels']\n",
    "\n",
    "    # Preprocess and Save all testing data\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(test_features), np.array(test_labels),\n",
    "                         'preprocess_training.p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting of Tensor-flow model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous weights, bias, inputs, etc..\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "# Inputs\n",
    "x =  tf1.placeholder(tf.float32, shape=(None, 32, 32, 3), name='input_x')\n",
    "y =  tf1.placeholder(tf.float32, shape=(None, 10), name='output_y')\n",
    "keep_prob = tf1.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Below one cell is function to implement fully connecetd layers (step 10-14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.layers import Dropout\n",
    "\n",
    "def fully_connected_layer():\n",
    "    \n",
    "    keep_prob=.2\n",
    "    model=tf.keras.Sequential()\n",
    "    \n",
    "    #10\n",
    "    model.add(layers.Dense(128,use_bias=True,input_shape=(2048,)))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.BatchNormalization())\n",
    "    #model.add(Dropout(keep_prob))\n",
    "    \n",
    "    #11\n",
    "    model.add(layers.Dense(256,use_bias=True))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.BatchNormalization())\n",
    "    #model.add(Dropout(keep_prob))\n",
    "    \n",
    "    #12\n",
    "    model.add(layers.Dense(512,use_bias=True))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.BatchNormalization())\n",
    "    #model.add(Dropout(keep_prob))\n",
    "    \n",
    "    #13\n",
    "    model.add(layers.Dense(1024,use_bias=True))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.BatchNormalization())\n",
    "    #model.add(Dropout(keep_prob))\n",
    "    \n",
    "    #14\n",
    "    model.add(layers.Dense(10,use_bias=True))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_net(x, keep_prob):\n",
    "    conv1_filter = tf.Variable(tf1.truncated_normal(shape=[3, 3, 3, 64], mean=0, stddev=0.08))\n",
    "    conv2_filter = tf.Variable(tf1.truncated_normal(shape=[3, 3, 64, 128], mean=0, stddev=0.08))\n",
    "    conv3_filter = tf.Variable(tf1.truncated_normal(shape=[5, 5, 128, 256], mean=0, stddev=0.08))\n",
    "    conv4_filter = tf.Variable(tf1.truncated_normal(shape=[5, 5, 256, 512], mean=0, stddev=0.08))\n",
    "\n",
    "    # 1, 2\n",
    "    conv1 = tf.nn.conv2d(x, conv1_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    print(conv1)\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    print(conv1)\n",
    "    conv1_pool = tf.nn.max_pool(conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    print(conv1_pool)\n",
    "    conv1_bn = tf1.layers.batch_normalization(conv1_pool)\n",
    "    print(conv1_bn)\n",
    "    \n",
    "\n",
    "    # 3, 4\n",
    "    conv2 = tf.nn.conv2d(conv1_bn, conv2_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2_pool = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')    \n",
    "    conv2_bn = tf1.layers.batch_normalization(conv2_pool)\n",
    "    \n",
    "    print(conv2)\n",
    "    print(conv2_pool)\n",
    "    print(conv2_bn)\n",
    "  \n",
    "    # 5, 6\n",
    "    conv3 = tf.nn.conv2d(conv2_bn, conv3_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "    conv3_pool = tf.nn.max_pool(conv3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')  \n",
    "    conv3_bn = tf1.layers.batch_normalization(conv3_pool)\n",
    "    \n",
    "    print(conv3)\n",
    "    print(conv3_pool)\n",
    "    print(conv3_bn)\n",
    "    \n",
    "    # 7, 8\n",
    "    conv4 = tf.nn.conv2d(conv3_bn, conv4_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv4 = tf.nn.relu(conv4)\n",
    "    conv4_pool = tf.nn.max_pool(conv4, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    conv4_bn = tf1.layers.batch_normalization(conv4_pool)\n",
    "    \n",
    "    print(conv4)\n",
    "    print(conv4_pool)\n",
    "    print(\"NITK\")\n",
    "    print(conv4_bn)\n",
    "    \n",
    "    # 9 Flatten\n",
    "    \n",
    "    ############################### From here Done by abhi. Check if working fine.\n",
    "    print(\" After flattening: \")\n",
    "    flat = tf.reshape(conv4_bn, [tf.shape(conv4_bn)[0], -1]) \n",
    "    #flat=tf.keras.backend.flatten(conv4_bn)\n",
    "    print(flat)\n",
    "    print(tf.size(flat))\n",
    "    \n",
    "    # 10\n",
    "    \n",
    "    #full1 = tf1.contrib.layers.fully_connected(inputs=flat, num_outputs=128, activation_fn=tf.nn.relu)\n",
    "    #full1 = tf.nn.dropout(full1, keep_prob)\n",
    "    #full1 = tf1.layers.batch_normalization(full1)\n",
    "    \n",
    "    # 11\n",
    "    #full2 = tf1.contrib.layers.fully_connected(inputs=full1, num_outputs=256, activation_fn=tf.nn.relu)\n",
    "    #full2 = tf.nn.dropout(full2, keep_prob)\n",
    "    #full2 = tf1.layers.batch_normalization(full2)\n",
    "    \n",
    "    # 12\n",
    "    #full3 = tf1.contrib.layers.fully_connected(inputs=full2, num_outputs=512, activation_fn=tf.nn.relu)\n",
    "    #full3 = tf.nn.dropout(full3, keep_prob)\n",
    "    #full3 = tf1.layers.batch_normalization(full3)    \n",
    "    \n",
    "    # 13\n",
    "    #full4 = tf1.contrib.layers.fully_connected(inputs=full3, num_outputs=1024, activation_fn=tf.nn.relu)\n",
    "    #full4 = tf.nn.dropout(full4, keep_prob)\n",
    "    #full4 = tf1.layers.batch_normalization(full4)        \n",
    "    \n",
    "    # 14\n",
    "    #out = tf1.contrib.layers.fully_connected(inputs=full3, num_outputs=10, activation_fn=None)\n",
    "    #return out\n",
    "    \n",
    "    #NEW 10-14\n",
    "    print(\"Entered fully connected layer\")\n",
    "    generator = fully_connected_layer()\n",
    "    final_output = generator(flat, training=False)\n",
    "    print(final_output)\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "keep_probability = 0.7\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_20:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "Tensor(\"Relu_20:0\", shape=(?, 32, 32, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_20:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "Tensor(\"batch_normalization_36/FusedBatchNormV3:0\", shape=(?, 16, 16, 64), dtype=float32)\n",
      "Tensor(\"Relu_21:0\", shape=(?, 16, 16, 128), dtype=float32)\n",
      "Tensor(\"MaxPool_21:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "Tensor(\"batch_normalization_37/FusedBatchNormV3:0\", shape=(?, 8, 8, 128), dtype=float32)\n",
      "Tensor(\"Relu_22:0\", shape=(?, 8, 8, 256), dtype=float32)\n",
      "Tensor(\"MaxPool_22:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"batch_normalization_38/FusedBatchNormV3:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"Relu_23:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "Tensor(\"MaxPool_23:0\", shape=(?, 2, 2, 512), dtype=float32)\n",
      "NITK\n",
      "Tensor(\"batch_normalization_39/FusedBatchNormV3:0\", shape=(?, 2, 2, 512), dtype=float32)\n",
      " After flattening: \n",
      "Tensor(\"Reshape_5:0\", shape=(?, ?), dtype=float32)\n",
      "Tensor(\"Size_5:0\", shape=(), dtype=int32)\n",
      "Entered fully connected layer\n",
      "Tensor(\"sequential_5/dense_24/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "logits= Tensor(\"sequential_5/dense_24/BiasAdd:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logits = conv_net(x, keep_prob)\n",
    "print(\"logits=\",logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.identity(logits, name='logits') # Name logits Tensor, so that can be loaded from disk after training\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf1.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "name: \"Adam\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam/update_Variable_20/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_Variable_21/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_Variable_22/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_Variable_23/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_batch_normalization_20/gamma/ApplyAdam\"\n",
      "input: \"^Adam/update_batch_normalization_20/beta/ApplyAdam\"\n",
      "input: \"^Adam/update_batch_normalization_21/gamma/ApplyAdam\"\n",
      "input: \"^Adam/update_batch_normalization_21/beta/ApplyAdam\"\n",
      "input: \"^Adam/update_batch_normalization_22/gamma/ApplyAdam\"\n",
      "input: \"^Adam/update_batch_normalization_22/beta/ApplyAdam\"\n",
      "input: \"^Adam/update_batch_normalization_23/gamma/ApplyAdam\"\n",
      "input: \"^Adam/update_batch_normalization_23/beta/ApplyAdam\"\n",
      "input: \"^Adam/update_dense_20/kernel/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_dense_20/bias/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_batch_normalization_40/gamma/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_batch_normalization_40/beta/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_dense_21/kernel/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_dense_21/bias/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_batch_normalization_41/gamma/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_batch_normalization_41/beta/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_dense_22/kernel/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_dense_22/bias/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_batch_normalization_42/gamma/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_batch_normalization_42/beta/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_dense_23/kernel/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_dense_23/bias/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_batch_normalization_43/gamma/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_batch_normalization_43/beta/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_dense_24/kernel/ResourceApplyAdam\"\n",
      "input: \"^Adam/update_dense_24/bias/ResourceApplyAdam\"\n",
      "input: \"^Adam/AssignVariableOp\"\n",
      "input: \"^Adam/AssignVariableOp_1\"\n",
      "\n",
      "Tensor(\"Equal_1:0\", shape=(?,), dtype=bool)\n",
      "Tensor(\"accuracy_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(cost)\n",
    "print(optimizer)\n",
    "print(correct_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    session.run(optimizer, \n",
    "                feed_dict={\n",
    "                    x: feature_batch,\n",
    "                    y: label_batch,\n",
    "                    keep_prob: keep_probability\n",
    "                })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    loss = sess.run(cost, \n",
    "                    feed_dict={\n",
    "                        x: feature_batch,\n",
    "                        y: label_batch,\n",
    "                        keep_prob: 1.\n",
    "                    })\n",
    "    valid_acc = sess.run(accuracy, \n",
    "                         feed_dict={\n",
    "                             x: valid_features,\n",
    "                             y: valid_labels,\n",
    "                             keep_prob: 1.\n",
    "                         })\n",
    "    \n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Fully training the model as shown in refernce link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]\n",
    "\n",
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
    "    features, labels = pickle.load(open(filename, mode='rb'))\n",
    "\n",
    "    # Return the training data in batches of size <batch_size> or less\n",
    "    return batch_features_labels(features, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  "
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[5000,32,32,64] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node Conv2D_20 (defined at /home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nOriginal stack trace for 'Conv2D_20':\n  File \"/home/abhi/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/abhi/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/abhi/anaconda3/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"/home/abhi/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"/home/abhi/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-77-b4c3d0652d4b>\", line 1, in <module>\n    logits = conv_net(x, keep_prob)\n  File \"<ipython-input-74-1867c4d4dedf>\", line 8, in conv_net\n    conv1 = tf.nn.conv2d(x, conv1_filter, strides=[1,1,1,1], padding='SAME')\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 1913, in conv2d_v2\n    name=name)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 2010, in conv2d\n    name=name)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 1071, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 793, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3360, in create_op\n    attrs, op_def, compute_device)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3429, in _create_op_internal\n    op_def=op_def)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1751, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[5000,32,32,64] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node Conv2D_20}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-4e55ccbbace9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {:>2}, CIFAR-10 Batch {}:  '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mprint_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Save Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-873b3138f47b>\u001b[0m in \u001b[0;36mprint_stats\u001b[0;34m(session, feature_batch, label_batch, cost, accuracy)\u001b[0m\n\u001b[1;32m     10\u001b[0m                              \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalid_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                              \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                              \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                          })\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[5000,32,32,64] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node Conv2D_20 (defined at /home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nOriginal stack trace for 'Conv2D_20':\n  File \"/home/abhi/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/abhi/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/abhi/anaconda3/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"/home/abhi/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"/home/abhi/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-77-b4c3d0652d4b>\", line 1, in <module>\n    logits = conv_net(x, keep_prob)\n  File \"<ipython-input-74-1867c4d4dedf>\", line 8, in conv_net\n    conv1 = tf.nn.conv2d(x, conv1_filter, strides=[1,1,1,1], padding='SAME')\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 1913, in conv2d_v2\n    name=name)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 2010, in conv2d\n    name=name)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 1071, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 793, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3360, in create_op\n    attrs, op_def, compute_device)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3429, in _create_op_internal\n    op_def=op_def)\n  File \"/home/abhi/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1751, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf1.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf1.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "                \n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
